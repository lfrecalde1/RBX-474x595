{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e24a61ce",
   "metadata": {},
   "source": [
    "# P0: Alohomora!\n",
    "# Part1:\n",
    "## Table Of Content\n",
    "\n",
    "1. What Is Convolution?\n",
    "2. Software Setup\n",
    "3. Convolution Methods\n",
    "    - Part-A.1: Keep Calm And Use `scipy.signal.convolve2d`\n",
    "    - Part-A.2: Slow And Steady: Applying Convolution With For-Loops\n",
    "    - Part-A.3: Lets Torch It\n",
    "4. Grading\n",
    "5. Report guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe62ee-b2c7-4a70-9209-469dc3de7b14",
   "metadata": {},
   "source": [
    "## 1. What is Convolution?\n",
    "\n",
    "Convolution is a fundamental operation in image processing, computer vision, and deep learning. It plays a crucial role in extracting features from images, enabling the detection of edges, textures, and patterns. At its core, convolution involves the application of a filter or kernel to an image, transforming it into a new representation that highlights specific features. Read up on [Convolution](https://en.wikipedia.org/wiki/Convolution) from Wikipedia for more details.\n",
    "\n",
    "Convolution is a mathematical operation that takes two inputs: an image (a 2D matrix of pixel values) and a kernel (a smaller matrix, often called a filter). The kernel is systematically moved (or convolved) across the image, and at each position, the element-wise product of the overlapping pixels is summed to produce a new pixel value in the output image. This process effectively combines the original image's information with the filter's characteristics, emphasizing certain features such as edges or textures.\n",
    "\n",
    "#### The Jargon:\n",
    "\n",
    "- **Kernel (Filter):** A small matrix used in convolution to modify the image. [Common kernels](https://en.wikipedia.org/wiki/Kernel_(image_processing)) include Gaussian, Sobel or Prewitt operators.\n",
    "- **Stride:** The step size with which the kernel moves across the image. A stride of 1 means the kernel moves one pixel at a time, while a larger stride results in a more significant jump between positions.\n",
    "- **Padding:** Padding involves adding extra pixels (usually zeros) around the edges of the image to control the size of the output image. Without padding, the output image will be smaller than the input.\n",
    "- **Convolution vs. Cross-Correlation:** In true convolution, the kernel is flipped before being applied (by element-wise dot product and summation) to the image. In cross-correlation, the kernel is used as-is. While convolution is the traditional mathematical operation, many libraries (including deep learning frameworks) use cross-correlation due to its simplicity and efficiency. In this project, you will be applying **convolution** operation and **not cross-correlation**. \n",
    "\n",
    "#### Applications of Convolution:\n",
    "\n",
    "Convolution is widely used in various fields, particularly in image processing and deep learning:\n",
    "- **Edge Detection:** Kernels designed to highlight edges can be convolved with an image to reveal its structure and boundaries.\n",
    "- **Blurring and Smoothing:** Convolution with a uniform kernel can smooth out noise and details, resulting in a blurred image.\n",
    "- **Feature Extraction:** In deep learning, convolutional layers automatically learn kernels that extract hierarchical features from images, enabling tasks such as object detection, classification, and segmentation.\n",
    "\n",
    "#### Summary of this project\n",
    "In this project, you will implement convolution in three different ways. This hands-on approach will deepen your understanding of how convolution functions, implementation issues and its significance in image analysis.\n",
    "\n",
    "Here is a sample output.\n",
    "\n",
    "![Minion](./sample/sample.png)\n",
    "\n",
    "\n",
    "**Filter Specification:**\n",
    "\n",
    "- Filter stride must be 1.\n",
    "- The image dimension must not change after filtering operation (use only zeroes for padding).\n",
    "- Output should be in double datatype. Please cast your input images to double before the filtering operation.\n",
    "- Use the provided kernel (KERNEL) only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3f154",
   "metadata": {},
   "source": [
    "## 2. Software Setup\n",
    "\n",
    "Ubuntu is the only supported platform for all the assignments in this course. You are responsible for installing the required packages yourself. We highly recommend using a virtual environment, such as venv or conda, to manage dependencies and maintain a clean development setup.\n",
    "\n",
    "The outputs from your functions will be saved as image files to assist you in debugging.\n",
    "\n",
    "The functions you complete will be evaluated using an automated test.py script. To check if your implementations pass the tests, open a terminal in the current folder and run python test.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fc6d2ec1-864b-4913-8938-4138822074eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import nbimporter\n",
    "import unittest\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "\n",
    "image_pil = Image.open('main.jpg').convert('L')\n",
    "image = np.array(image_pil)\n",
    "KERNEL = np.array([[1, 0, -1], [2, 0, -2],[1, 0, -1]], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fb4c8b80-5e0d-46a0-87ab-7493732662cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the format of the image to double and normalize\n",
    "#img = image.astype(np.float64)/255\n",
    "\n",
    "# Check Convolution\n",
    "#edges   = convolve2d(img, KERNEL, mode='same', boundary='fill', fillvalue=0.0)\n",
    "\n",
    "# Save original image and \n",
    "#writeDoubleImage(edges, \"filter_unity.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32d80e",
   "metadata": {},
   "source": [
    "## 3. Convolution Methods\n",
    "### Part1.1: Keep Calm And Use `scipy.signal.convolve2d`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457da33",
   "metadata": {},
   "source": [
    "Several libraries provide standard implementations of convolution filters for image processing tasks. In this section, you will implement convolution using `scipy.signal.convolve2d`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090a747",
   "metadata": {},
   "source": [
    "Using the convolve2d function from the scipy.signal module, apply a convolution filter to an RGB image below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e92b6523-92d7-4d92-99d4-16b478ac033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_scipy_convolve2d(img, kernel):\n",
    "    start =time.time()\n",
    "    filtered_image = np.zeros_like(img).astype(np.float64)\n",
    "    \n",
    "    # Write Your Code Here!\n",
    "    img = img.astype(np.float64)/255\n",
    "    \n",
    "\n",
    "    # Check Convolution\n",
    "    filtered_image   = convolve2d(img, kernel, mode='same', boundary='fill', fillvalue=0.0)\n",
    "    \n",
    "    print(\"Elapsed time (s)=\", time.time() - start)\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "91e04534-2484-4faf-b686-349b8ca276de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time (s)= 0.02126336097717285\n"
     ]
    }
   ],
   "source": [
    "img_scipy = filter_scipy_convolve2d(image, KERNEL)\n",
    "#writeDoubleImage(img, \"scipy.jpg\")\n",
    "writeDoubleImage(img_scipy, \"scipy.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "39b39266-6235-4aaa-88c7-db0b23048fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf2b518c-a8e4-4061-bc2a-4a4b2b229ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac79e5b5",
   "metadata": {},
   "source": [
    "### Part1.2: Slow And Steady: Applying Convolution With For-Loops\n",
    "\n",
    "Now implement the same functionality using \"for\" loop. The output image should have the same shape as input. Use zeroes for padding the input image at edges so that the output image has the same shape as input after convolution.\n",
    "\n",
    "Hint -  You can pad the input matrix with zeros using np.pad. For flipping the kernel, use np.flip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8d0ead7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_numpy_for_loop(img, kernel):\n",
    "    start = time.time()\n",
    "    kernel = np.flip(kernel)\n",
    "    filtered_image = np.zeros_like(img).astype(np.float64)\n",
    "    img = img.astype(np.float64)/255\n",
    "    \n",
    "    # Add zero padding to the input image\n",
    "    size_padding = kernel.shape[0]//2\n",
    "    kernel_size = kernel.shape[0]\n",
    "    img_pad = np.pad(img, ((size_padding, size_padding), (size_padding, size_padding)), mode='constant', constant_values=0.0)\n",
    "\n",
    "    #Loop over every pixel of the image\n",
    "    for u in range(img.shape[0]):\n",
    "       for v in range(img.shape[1]):\n",
    "           filtered_image[u, v]=(kernel * img_pad[u: u+kernel_size, v: v+kernel_size]).sum()\n",
    "\n",
    "    print(\"Elapsed time (s)=\", time.time() - start)\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cef31b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time (s)= 1.2054808139801025\n"
     ]
    }
   ],
   "source": [
    "img_for = filter_numpy_for_loop(image, KERNEL)\n",
    "writeDoubleImage(img_for, \"numpy_for_loop.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf4564b",
   "metadata": {},
   "source": [
    "### Part1.3: Lets Torch It\n",
    "Convolutional filters (conv filters) are small, learnable matrices used in convolutional neural networks (CNNs) to detect patterns such as edges, textures, or shapes in input data. By sliding over the input (e.g., an image), they compute dot products to create feature maps, highlighting specific aspects of the data relevant for tasks like classification or detection.\n",
    "\n",
    "In the next section, you will use a Conv. layer with hard-coded weights to perform the same task. You must use a [conv2d layer](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) with hard-coded kernel. Make sure you flip the kernel using np.flip(kernel).copy()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dcb6ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_torch(img, kernel):\n",
    "    start = time.time()\n",
    "\n",
    "    # Write Your Code Here\n",
    "    img_t = torch.from_numpy(img).float().div(255.0)[None, None, ...]\n",
    "\n",
    "    kernel = kernel.astype(np.float32)\n",
    "    K_flipped = torch.from_numpy(kernel).flip(0,1)          \n",
    "    weight = K_flipped.view(1, 1, 3, 3)                 \n",
    "\n",
    "    # Output Convolution\n",
    "    filtered_image = F.conv2d(img_t, weight, padding=1)            \n",
    "    print(\"Elapsed time (s)=\", time.time() - start)\n",
    "    return filtered_image.squeeze(0).squeeze(0).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8ef91c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time (s)= 0.015315532684326172\n"
     ]
    }
   ],
   "source": [
    "img_torch = filter_torch(image, KERNEL)\n",
    "writeDoubleImage(img_torch, \"torch_conv.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffca56c",
   "metadata": {},
   "source": [
    "## 4. Grading Rubric for Part1\n",
    "\n",
    "- Part1.1 25%\n",
    "- Part1.2 25%\n",
    "- Part1.3 25%\n",
    "- Report   25%\n",
    "\n",
    "## 5. Report Guidelines:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7754fee8",
   "metadata": {},
   "source": [
    "- Include the execution time for all three techniques. If there are differences, explain the reasons behind them.\n",
    "- The report must include both the expected ground truth (from the test.py code) and the achieved convolved images.\n",
    "- Clearly describe the filtering operation being performed and explain the role of the kernel. Support your explanation with evidence, using images from different scenarios to illustrate your points.\n",
    "- What is happening in the kernel you used and why does it work?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
